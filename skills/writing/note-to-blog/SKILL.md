---
name: note-to-blog
description: Use when user wants to find a note to publish as a blog post. Triggers onã€Œé€‰ä¸€ç¯‡ç¬”è®°å‘åšå®¢ã€ã€Œnote to blogã€ã€Œå†™åšå®¢ã€ã€Œåšå®¢é€‰é¢˜ã€. Scans Obsidian vault for blog-ready candidates.
---

# Note to Blog

ä» Obsidian Note ä»“åº“ä¸­ç­›é€‰é€‚åˆå‘å¸ƒçš„ç¬”è®°ï¼Œè¯„ä¼°é€‚é…æ€§ï¼Œæ‰¹é‡é€‰é¢˜ï¼ŒåŒé€šé“å¤„ç†ï¼ˆå¿«é€Ÿè½¬æ¢ / æ·±åº¦ç ”ç©¶ï¼‰ï¼Œå¹¶è¡Œ Agent æ´¾å‘ã€‚

## Prerequisites

| Tool | Type | Required | Install |
|------|------|----------|---------|
| Python 3 | cli | Yes | Pre-installed on macOS |
| PyYAML | cli | Yes | `pip install pyyaml` |
| writing-proofreading | skill | No | Included in `npx skills add niracler/skill` |

> Do NOT proactively verify these tools on skill load. If a command fails due to a missing tool, directly guide the user through installation and configuration step by step.

## When NOT to Use

- ç¬”è®°åº“å°‘äº 5 ç¯‡æ—¶ï¼Œæ‰‹åŠ¨é€‰é¢˜æ›´å¿«
- åªæƒ³è½¬æ¢å•ç¯‡å·²ç¡®å®šçš„ç¬”è®° â€” ç›´æ¥è¿è¡Œ `<skill-dir>/scripts/note-to-blog.py convert "<path>"`
- åšå®¢è‰ç¨¿å·²å­˜åœ¨ï¼Œåªéœ€æ ¡å¯¹ â€” ä½¿ç”¨ writing-proofreading

## Script Location

All deterministic operations are handled by the Python script:

```text
<skill-dir>/scripts/note-to-blog.py  (collect / convert / state subcommands)
```

Path configuration is in [user-config.md](references/user-config.md). All bash examples below use `<PLACEHOLDER>` â€” replace with values from user-config.md.

## Workflow Overview

```text
Step 1           Step 2            Step 3              Step 4             Step 5
 Collect   â”€â”€â–¶   Level Select â”€â”€â–¶  By Level     â”€â”€â–¶   Execute      â”€â”€â–¶   Summary
 (script)        (user)            â”œâ”€ L1 æµè§ˆ          (Agent Teams)       (report)
                                   â”œâ”€ L2 æ¨è
                                   â””â”€ L3 æ·±æ¢
                                        â”‚
                                   Interact â”€â”€â–¶ track assign â”€â”€â–¶ confirm
```

## Step 1: Collect

Run the `collect` script with paths from [user-config.md](references/user-config.md):

```bash
python3 <skill-dir>/scripts/note-to-blog.py collect \
  --note-repo "<NOTE_REPO>" \
  --blog-content "<BLOG_CONTENT>" \
  --project-paths <PROJECT_PATHS> \
  --history-file "<HISTORY_FILE>"
```

The script outputs a single JSON object to stdout containing:

- `candidates`: all eligible notes with title, summary, char_count, outgoing_links
- `clusters`: wikilink hub nodes (3+ inbound links) with related notes
- `published_posts`: existing blog posts with title, tags, collection
- `session_keywords`: recent Claude Code session activity signals
- `stats`: total_scanned, filtered_out, candidates_count

Read the JSON output and proceed to Step 2.

## Step 2: Level Selection

Display data volume and offer Level choice:

```text
collect å®Œæˆï¼š
  å€™é€‰ç¬”è®°: {candidates_count} ç¯‡ (æ€»æ‰«æ {total_scanned}, è¿‡æ»¤ {filtered_out})
  ä¸»é¢˜ç°‡: {clusters_count} ä¸ª (3+ å¼•ç”¨ hub)

å¯é€‰æ·±åº¦:
  Level 1 æµè§ˆ    ç›´æ¥å±•ç¤ºå€™é€‰åˆ—è¡¨ï¼Œæ‰‹åŠ¨é€‰æ‹©          0 é¢å¤– token
  Level 2 æ¨è    LLM è¯„ä¼° + ä¸»é¢˜ç°‡åˆ†æ              ~2k token     â† æ¨è
  Level 3 æ·±æ¢    Level 2 + è¯»å– hub ç¬”è®°å…¨æ–‡         ~5k+ token

é€‰æ‹© Level (1-3)?
```

### Quick Reference

| Level | åç§° | è¯„ä¼°æ–¹å¼ | åç»­æµç¨‹ |
|:---:|:---|:---|:---|
| 1 | æµè§ˆ | æ—  LLMï¼Œå€™é€‰æŒ‰å­—æ•°é™åº | ç”¨æˆ·ç›´é€‰ â†’ å…¨éƒ¨ fast track |
| 2 | æ¨è | LLM è¯„ä¼°æ‘˜è¦ + ä¸»é¢˜ç°‡ â†’ 5-8 æ¨è | fast/deep track åˆ†é… |
| 3 | æ·±æ¢ | Level 2 + è¯»å– hub ç¬”è®°å…¨æ–‡ | fast/deep trackï¼Œcluster æ¨èæ›´å‡†ç¡® |

### Recommendation logic

| å€™é€‰æ•° | clusters | æ¨è |
|--------|----------|------|
| â‰¤ 10 | any | Level 1 |
| > 10 | 0 | Level 2 |
| > 10 | 1+ | Level 2 |

ç”¨æˆ·æ˜ç¡®è¯´ã€Œæƒ³å‘ç°ä¸»é¢˜ã€ã€Œæœ‰ä»€ä¹ˆå¯ä»¥æ•´åˆçš„ã€æ—¶ â†’ æ¨è Level 3ã€‚

## Step 3: By Level

### Level 1: Browse

Skip LLM evaluation. Display candidates sorted by char_count descending:

```text
#  æ ‡é¢˜                         å­—æ•°    é“¾æ¥æ•°
1  å…³äºåLLMæ—¶ä»£çš„ä»£ç Review     3200    5
2  SSHç§é’¥åŠ å¯†                   1200    2
3  Feedå†…å®¹é˜…è¯»å§¿åŠ¿              1800    3
...
```

User selects items by number. All selections go to **fast track only** (Level 1 does not offer deep track).

After selection, skip to **Confirm & Execute** below.

### Level 2: Recommend

Make a single LLM evaluation using the prompt template from [scoring-criteria.md](references/scoring-criteria.md).

**Input**: Construct the evaluation prompt with `collect` JSON data (candidates, clusters, published_posts, session_keywords).

**Output**: The LLM SHALL return a JSON array of 5-8 recommendations. See [scoring-criteria.md](references/scoring-criteria.md) for the full specification.

If the LLM response is not valid JSON, retry once with explicit format instructions.

After evaluation, proceed to **Interact** below.

### Level 3: Deep Explore

Same as Level 2, but **before** calling the LLM, Read the full text of each cluster hub note and append it to the evaluation prompt.

For each cluster in the collect JSON where `hub_path` is not null:

1. Read the hub note full text from the Note repository
2. Append it to the LLM prompt under a `## Hub ç¬”è®°å…¨æ–‡` section (see [scoring-criteria.md](references/scoring-criteria.md) for the Level 3 input format)

This gives the LLM actual content context for cluster recommendations instead of just metadata.

After evaluation, proceed to **Interact** below.

## Interact (Level 2/3)

### Present recommendations

Display the recommendation list as a mixed table:

```text
#  ç±»å‹    æ ‡é¢˜                    é€‚é…åˆ†  ç›®æ ‡   å·¥ä½œé‡  æ´»è·ƒ   é‡å¤é£é™©
1  å•ç¯‡    åLLMæ—¶ä»£ä»£ç Review      92    blog    å°    â˜…â˜…â˜…    æ— 
2  ä¸»é¢˜ç°‡  ä¼˜é›…çš„å“²å­¦ (9ç¯‡å…³è”)      88    blog    å¤§    â˜…      æ— 
3  å•ç¯‡    SSHç§é’¥åŠ å¯†              85    til     å°    â”€      æ— 
...
```

### User actions

| Action | Example | Effect |
|--------|---------|--------|
| Select + assign track | "1 å’Œ 3 å¿«é€Ÿè½¬æ¢ï¼Œ2 èµ°æ·±åº¦" | Queue items with track assignment |
| Override collection | "1 æ”¾ til" | Change target collection |
| Batch skip | "4~6 è·³è¿‡ï¼Œreason: private" | Mark as skipped via `state skip` |
| See more | "è¿˜æœ‰åˆ«çš„å—" | Request additional recommendations |
| Check status | "çŠ¶æ€" | Run `state status` |

**On skip**: run immediately:

```bash
python3 <skill-dir>/scripts/note-to-blog.py state skip "<path>" --reason "<reason>" \
  --note-repo "<NOTE_REPO>"
```

### Track assignment

| Track | When to use | What happens |
|-------|-------------|--------------|
| **Fast** (å¿«é€Ÿ) | Independent, mostly complete notes | Script converts â†’ Agent reviews â†’ draft |
| **Deep** (æ·±åº¦) | Topic clusters or rough notes needing research | Agent reads all related notes â†’ research report |

Default: `effort: "å°"` â†’ fast; `type: "cluster"` or `effort: "å¤§"` â†’ deep. User decides.

## Confirm & Execute

Display a confirmation summary (all Levels):

```text
ç¡®è®¤é€‰æ‹©ï¼š
  Fast track:
    1. åLLMæ—¶ä»£ä»£ç Review â†’ blog/
    3. SSHç§é’¥åŠ å¯† â†’ til/
  Deep track:
    2. ä¼˜é›…çš„å“²å­¦ (9ç¯‡å…³è”) â†’ blog/

å¼€å§‹å¤„ç†ï¼Ÿ
```

Wait for user confirmation, then dispatch.

### Parallel dispatch

Dispatch N parallel Agents using the Task tool, one per selected item.

> å…¶ä»– Agent ç¯å¢ƒï¼šä»¥ä¸‹ Fast/Deep track ä»»åŠ¡ç›¸äº’ç‹¬ç«‹ï¼Œå¯æŒ‰é¡ºåºä¾æ¬¡æ‰§è¡Œã€‚

```text
æ€»ç¼– (Main Agent)
â”œâ”€â”€ Task Agent 1: æ–‡ç«  A (fast track)
â”œâ”€â”€ Task Agent 2: æ–‡ç«  B (fast track)
â””â”€â”€ Task Agent 3: ä¸»é¢˜ç°‡ C (deep track)
```

Use the Task tool to launch all Agents in a single message. Each Agent should be a `general-purpose` subagent with a detailed prompt containing all the information it needs.

See [agent-instructions.md](references/agent-instructions.md) for the complete Fast Track and Deep Track agent prompt templates.

### State updates

Individual Agents do NOT update `.note-to-blog.json` directly. After all Agents complete, the main agent runs state updates sequentially:

```bash
python3 <skill-dir>/scripts/note-to-blog.py state draft "<note_path>" \
  --target "<collection>/<slug>.md" \
  --note-repo "<NOTE_REPO>"
```

Deep track items are NOT marked as drafted (they need further user decision).

## Summary

After all Agents complete, present a unified summary:

```text
Fast Track å®Œæˆï¼š
  âœ“ åLLMæ—¶ä»£ä»£ç Review â†’ repos/bokushi/src/content/blog/llm-code-review.md
    - è½¬æ¢æ­£å¸¸ï¼Œæ— é—®é¢˜
  âœ“ SSHç§é’¥åŠ å¯† â†’ repos/bokushi/src/content/til/ssh-key-encryption.md
    - å‘ç° 1 ä¸ª TODO æ ‡è®°éœ€è¦æ‰‹åŠ¨å¤„ç†

Deep Track å®Œæˆï¼š
  ğŸ“‹ ä¼˜é›…çš„å“²å­¦ (9ç¯‡å…³è”)
    - ç ”ç©¶æŠ¥å‘Šå·²ç”Ÿæˆ
    - ä¸‹ä¸€æ­¥ï¼Ÿ a) æŒ‰å¤§çº²å†™ä½œ  b) ä¿®æ”¹å¤§çº²  c) æš‚ä¸å¤„ç†

çŠ¶æ€æ›´æ–°ï¼š
  drafted: N ç¯‡

è‰ç¨¿å‡ä¸º hidden: trueï¼Œéœ€è¦æ‰‹åŠ¨ review åæ”¹ä¸º false å‘å¸ƒã€‚
å»ºè®®ä½¿ç”¨ /writing-proofreading è¿›è¡Œå®¡æ ¡ã€‚

å‘å¸ƒåè¿è¡Œ:
  python3 <skill-dir>/scripts/note-to-blog.py state publish "<note_path>" --note-repo "<NOTE_REPO>"
```

## Detailed References

- Path configuration: [user-config.md](references/user-config.md)
- LLM evaluation prompt and scoring: [scoring-criteria.md](references/scoring-criteria.md)
- Agent prompt templates: [agent-instructions.md](references/agent-instructions.md)
